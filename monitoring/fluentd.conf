# Fluentd Configuration for WhatsApp SaaS Log Aggregation

# Input Sources
<source>
  @type tail
  path /app/logs/combined-*.log
  pos_file /var/log/fluentd/combined.log.pos
  tag whatsapp.saas.api.combined
  format json
  time_key timestamp
  time_format %Y-%m-%d %H:%M:%S.%L
  refresh_interval 60
  read_from_head true
</source>

<source>
  @type tail
  path /app/logs/error-*.log
  pos_file /var/log/fluentd/error.log.pos
  tag whatsapp.saas.api.error
  format json
  time_key timestamp
  time_format %Y-%m-%d %H:%M:%S.%L
  refresh_interval 60
  read_from_head true
</source>

<source>
  @type tail
  path /app/logs/access-*.log
  pos_file /var/log/fluentd/access.log.pos
  tag whatsapp.saas.api.access
  format json
  time_key timestamp
  time_format %Y-%m-%d %H:%M:%S.%L
  refresh_interval 60
  read_from_head true
</source>

# Worker service logs
<source>
  @type tail
  path /worker/logs/*.log
  pos_file /var/log/fluentd/worker.log.pos
  tag whatsapp.saas.worker
  format json
  time_key timestamp
  time_format %Y-%m-%d %H:%M:%S.%L
  refresh_interval 60
  read_from_head true
</source>

# Docker container logs
<source>
  @type forward
  port 24224
  tag docker
</source>

# System metrics via fluent-plugin-systemd
<source>
  @type systemd
  tag systemd
  path /var/log/journal
  matches [{ "_SYSTEMD_UNIT": "whatsapp-saas-api.service" }, { "_SYSTEMD_UNIT": "whatsapp-saas-worker.service" }]
  read_from_head true
  strip_underscores true
</source>

# Prometheus metrics collection
<source>
  @type prometheus
  bind 0.0.0.0
  port 24231
  metrics_path /metrics
</source>

<source>
  @type prometheus_monitor
  interval 10
</source>

# Log Processing and Enrichment
<filter whatsapp.saas.**>
  @type record_transformer
  <record>
    service ${tag_parts[1]}
    environment ${ENV["ENVIRONMENT"]}
    cluster ${ENV["CLUSTER_NAME"]}
    node_name ${ENV["NODE_NAME"]}
    pod_name ${ENV["POD_NAME"]}
    namespace ${ENV["NAMESPACE"]}
  </record>
</filter>

# Parse and enrich HTTP access logs
<filter whatsapp.saas.api.access>
  @type parser
  key_name message
  reserve_data true
  <parse>
    @type json
  </parse>
</filter>

<filter whatsapp.saas.api.access>
  @type record_transformer
  <record>
    log_type access
    response_time_ms ${record["responseTime"]}
    status_code_class ${record["statusCode"][0]}xx
    is_error ${record["statusCode"] >= 400}
    is_slow ${record["responseTime"] > 1000}
  </record>
</filter>

# Parse and enrich error logs
<filter whatsapp.saas.api.error>
  @type record_transformer
  <record>
    log_type error
    severity high
    alert_required true
  </record>
</filter>

# GeoIP enrichment for IP addresses
<filter whatsapp.saas.api.access>
  @type geoip
  geoip_lookup_keys ip
  <record>
    geoip_country ${geoip_country_name["ip"]}
    geoip_city ${geoip_city_name["ip"]}
    geoip_region ${geoip_region_name["ip"]}
  </record>
  skip_adding_null_record true
</filter>

# User-Agent parsing
<filter whatsapp.saas.api.access>
  @type ua_parser
  key_name userAgent
  delete_key true
  out_key ua
</filter>

# Log sampling for high-volume endpoints
<filter whatsapp.saas.api.access>
  @type sampling
  sample_rate 10
  <condition>
    key url
    pattern ^/health
  </condition>
</filter>

# Security log detection and enrichment
<filter whatsapp.saas.**>
  @type grep
  <regexp>
    key message
    pattern (suspicious|attack|intrusion|unauthorized|breach|malicious)
  </regexp>
  tag security_event
</filter>

<filter security_event>
  @type record_transformer
  <record>
    alert_type security
    severity critical
    requires_immediate_attention true
  </record>
</filter>

# Performance log detection
<filter whatsapp.saas.**>
  @type grep
  <regexp>
    key message
    pattern (slow|timeout|performance|bottleneck)
  </regexp>
  tag performance_issue
</filter>

<filter performance_issue>
  @type record_transformer
  <record>
    alert_type performance
    severity medium
  </record>
</filter>

# Business metrics extraction
<filter whatsapp.saas.**>
  @type grep
  <regexp>
    key message
    pattern Business metric
  </regexp>
  tag business_metric
</filter>

<filter business_metric>
  @type parser
  key_name message
  reserve_data true
  <parse>
    @type regexp
    expression /Business metric: (?<metric_name>\w+)/
  </parse>
</filter>

# Output Configuration

# Elasticsearch for log storage and search
<match whatsapp.saas.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  index_name whatsapp-saas-logs
  type_name _doc
  
  # Index template
  template_name whatsapp-saas
  template_file /fluentd/etc/elasticsearch-template.json
  template_overwrite true
  
  # Buffer configuration
  <buffer>
    @type file
    path /var/log/fluentd/elasticsearch.buffer
    flush_mode interval
    flush_interval 10s
    flush_thread_count 2
    retry_type exponential_backoff
    retry_wait 1s
    retry_max_interval 60s
    retry_timeout 60m
    chunk_limit_size 10m
    queue_limit_length 32
    overflow_action block
  </buffer>
  
  # Authentication (if required)
  user ${ELASTICSEARCH_USER}
  password ${ELASTICSEARCH_PASSWORD}
  
  # SSL configuration
  scheme https
  ssl_verify false
  
  # Log level for debugging
  log_level info
  
  # Suppress logs for health check endpoints
  suppress_type_name true
  
  # Request timeout
  request_timeout 30s
  
  # Error handling
  resurrect_after 5s
  reload_connections false
  reload_on_failure false
  
  # Performance tuning
  bulk_message_request_threshold 1048576
  enable_ilm true
  ilm_policy_id whatsapp-saas-policy
</match>

# CloudWatch Logs (for AWS deployment)
<match whatsapp.saas.**>
  @type cloudwatch_logs
  log_group_name /aws/whatsapp-saas
  log_stream_name ${tag}
  region ${AWS_REGION}
  
  <buffer>
    @type file
    path /var/log/fluentd/cloudwatch.buffer
    flush_mode interval
    flush_interval 60s
    chunk_limit_size 1m
  </buffer>
</match>

# Google Cloud Logging (for GCP deployment)
<match whatsapp.saas.**>
  @type google_cloud
  project_id ${GCP_PROJECT_ID}
  zone ${GCP_ZONE}
  
  <buffer>
    @type file
    path /var/log/fluentd/gcp.buffer
    flush_mode interval
    flush_interval 30s
  </buffer>
</match>

# Kafka for real-time log streaming
<match whatsapp.saas.**>
  @type kafka2
  brokers ${KAFKA_BROKERS}
  topic_key topic
  default_topic whatsapp-saas-logs
  
  # Message formatting
  <format>
    @type json
  </format>
  
  # Buffer configuration
  <buffer topic>
    @type file
    path /var/log/fluentd/kafka.buffer
    flush_mode interval
    flush_interval 5s
    chunk_limit_size 1m
  </buffer>
  
  # Producer configuration
  max_send_retries 3
  required_acks 1
  compression_codec gzip
</match>

# S3 for long-term log archival
<match whatsapp.saas.**>
  @type s3
  s3_bucket ${S3_LOG_BUCKET}
  s3_region ${AWS_REGION}
  path logs/%Y/%m/%d/
  s3_object_key_format %{path}%{time_slice}_%{index}.%{file_extension}
  
  # Buffer configuration
  <buffer time>
    @type file
    path /var/log/fluentd/s3.buffer
    timekey 3600
    timekey_wait 10m
    chunk_limit_size 256m
  </buffer>
  
  # Compression
  store_as gzip
  
  # Format
  <format>
    @type json
  </format>
</match>

# Alert routing for critical logs
<match security_event>
  @type http
  endpoint ${SECURITY_ALERT_WEBHOOK}
  http_method post
  
  <format>
    @type json
  </format>
  
  <buffer>
    @type memory
    flush_mode immediate
  </buffer>
  
  headers {"Content-Type": "application/json"}
</match>

# Prometheus metrics export
<match prometheus.metrics>
  @type prometheus
  <metric>
    name fluentd_output_status_num_records_total
    type counter
    desc The total number of outgoing records
    <labels>
      tag ${tag}
      hostname ${hostname}
    </labels>
  </metric>
</match>

# Dead letter queue for failed logs
<match **>
  @type file
  path /var/log/fluentd/failed-logs
  append true
  
  <format>
    @type json
  </format>
  
  <buffer>
    @type file
    path /var/log/fluentd/dlq.buffer
    flush_mode interval
    flush_interval 60s
  </buffer>
</match>

# System configuration
<system>
  log_level info
  process_name fluentd-whatsapp-saas
  
  # Enable RPC endpoint for monitoring
  rpc_endpoint 0.0.0.0:24444
  
  # Log rotation
  <log>
    format json
    time_format %Y-%m-%d %H:%M:%S %z
  </log>
</system>